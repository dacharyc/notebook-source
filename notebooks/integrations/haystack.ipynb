{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atlas Vector Search - Haystack Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a companion for the [Haystack](https://www.mongodb.com/docs/atlas/atlas-vector-search/ai-integrations/haystack/) page. Refer to the page for set up steps and explanation details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip --quiet install mongodb-atlas-haystack pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Pipeline, Document\n",
    "from haystack.document_stores.types import DuplicatePolicy\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "from haystack.components.builders.prompt_builder import PromptBuilder\n",
    "from haystack.components.embedders import OpenAITextEmbedder, OpenAIDocumentEmbedder\n",
    "from haystack_integrations.document_stores.mongodb_atlas import MongoDBAtlasDocumentStore\n",
    "from haystack_integrations.components.retrievers.mongodb_atlas import MongoDBAtlasEmbeddingRetriever\n",
    "from pymongo import MongoClient\n",
    "from pymongo.operations import SearchIndexModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"<api-key>\"\n",
    "ATLAS_CONNECTION_STRING = \"<connection-string>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(ATLAS_CONNECTION_STRING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your database and collection\n",
    "db_name = \"haystack_db\"\n",
    "collection_name = \"test\"\n",
    "database = client[db_name]\n",
    "database.create_collection(collection_name)\n",
    "\n",
    "# Define collection\n",
    "collection = client[db_name][collection_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your index model, then create the search index\n",
    "search_index_model = SearchIndexModel(\n",
    "   definition={\n",
    "      \"fields\": [\n",
    "         {\n",
    "            \"type\": \"vector\",\n",
    "            \"path\": \"embedding\",\n",
    "            \"numDimensions\": 1536,\n",
    "            \"similarity\": \"cosine\"\n",
    "         }\n",
    "      ]\n",
    "   },\n",
    "   name=\"vector_index\",\n",
    "   type=\"vectorSearch\"\n",
    ")\n",
    "\n",
    "collection.create_search_index(model=search_index_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store = MongoDBAtlasDocumentStore(\n",
    "   database_name=\"haystack_db\",\n",
    "   collection_name=\"test\",\n",
    "   vector_search_index=\"vector_index\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some example documents\n",
    "documents = [\n",
    "   Document(content=\"My name is Jean and I live in Paris.\"),\n",
    "   Document(content=\"My name is Mark and I live in Berlin.\"),\n",
    "   Document(content=\"My name is Giorgio and I live in Rome.\"),\n",
    "]\n",
    "\n",
    "# Initializing a document embedder to convert text content into vectorized form.\n",
    "doc_embedder = OpenAIDocumentEmbedder()\n",
    "\n",
    "# Setting up a document writer to handle the insertion of documents into the MongoDB collection.\n",
    "doc_writer = DocumentWriter(document_store=document_store, policy=DuplicatePolicy.SKIP)\n",
    "\n",
    "# Creating a pipeline for indexing documents. The pipeline includes embedding and writing documents.\n",
    "indexing_pipe = Pipeline()\n",
    "indexing_pipe.add_component(instance=doc_embedder, name=\"doc_embedder\")\n",
    "indexing_pipe.add_component(instance=doc_writer, name=\"doc_writer\")\n",
    "\n",
    "# Connecting the components of the pipeline for document flow.\n",
    "indexing_pipe.connect(\"doc_embedder.documents\", \"doc_writer.documents\")\n",
    "\n",
    "# Running the pipeline with the list of documents to index them in MongoDB.\n",
    "indexing_pipe.run({\"doc_embedder\": {\"documents\": documents}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template for generating prompts.\n",
    "prompt_template = \"\"\"\n",
    "    You are an assistant allowed to use the following context documents.\\nDocuments:\n",
    "    {% for doc in documents %}\n",
    "        {{ doc.content }}\n",
    "    {% endfor %}\n",
    "\n",
    "    \\nQuery: {{query}}\n",
    "    \\nAnswer:\n",
    "\"\"\"\n",
    "\n",
    "# Setting up a retrieval-augmented generation (RAG) pipeline for generating responses.\n",
    "rag_pipeline = Pipeline()\n",
    "rag_pipeline.add_component(\"text_embedder\", OpenAITextEmbedder())\n",
    "\n",
    "# Adding a component for retrieving related documents from MongoDB based on the query embedding.\n",
    "rag_pipeline.add_component(instance=MongoDBAtlasEmbeddingRetriever(document_store=document_store,top_k=15), name=\"retriever\")\n",
    "\n",
    "# Building prompts based on retrieved documents to be used for generating responses.\n",
    "rag_pipeline.add_component(instance=PromptBuilder(template=prompt_template), name=\"prompt_builder\")\n",
    "\n",
    "# Adding a language model generator to produce the final text output.\n",
    "rag_pipeline.add_component(instance=OpenAIGenerator(), name=\"llm\")\n",
    "\n",
    "# Connecting the components of the RAG pipeline to ensure proper data flow.\n",
    "rag_pipeline.connect(\"text_embedder.embedding\", \"retriever.query_embedding\")\n",
    "rag_pipeline.connect(\"retriever\", \"prompt_builder.documents\")\n",
    "rag_pipeline.connect(\"prompt_builder\", \"llm\")\n",
    "\n",
    "# Run the pipeline\n",
    "query = \"Where does Mark live?\"\n",
    "result = rag_pipeline.run(\n",
    "  {\n",
    "      \"text_embedder\": {\"text\": query},\n",
    "      \"prompt_builder\": {\"query\": query},\n",
    "  });\n",
    "print(result['llm']['replies'][0])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
